{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Self-Driving_Car_CNN.ipynb","provenance":[{"file_id":"https://github.com/dctian/DeepPiCar/blob/master/models/lane_navigation/code/end_to_end_lane_navigation.ipynb","timestamp":1620782138449}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EWOFWI88L6sj"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rihBIMTlM7rm"},"source":["# Mount my Google Drive.  It will ask for an authenticate code\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","model_output_dir = '/content/gdrive/My Drive/Colab Notebooks/LaneNavigation'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RFZEdyZPtdMG"},"source":["## Imports Packages"]},{"cell_type":"code","metadata":{"id":"6-BJrGUh00Cp"},"source":["# imports\n","\n","# python standard libraries\n","import os\n","import random\n","import fnmatch\n","import datetime\n","import pickle\n","\n","# data processing\n","import numpy as np\n","np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n","\n","import pandas as pd\n","pd.set_option('display.width', 300)\n","pd.set_option('display.float_format', '{:,.4f}'.format)\n","pd.set_option('display.max_colwidth', 200)\n","\n","# tensorflow\n","import tensorflow as tf\n","import keras\n","from keras.models import Sequential  # V2 is tensorflow.keras.xxxx, V1 is keras.xxx\n","from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n","from keras.optimizers import Adam\n","from keras.models import load_model\n","\n","print( f'tf.__version__: {tf.__version__}' )\n","print( f'keras.__version__: {keras.__version__}' )\n","\n","# sklearn\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","# imaging\n","import cv2\n","from imgaug import augmenters as img_aug\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","from PIL import Image\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwN2MO3jP-13"},"source":["#################### SEND ALERT EMAIL AT FINISH WITH GMAIL #####################\n","# To send email from Python from your google account, MUST \n","# 1) Enable less secure app\n","# https://myaccount.google.com/lesssecureapps\n","# 2) Disable Unlock Capcha\n","# https://accounts.google.com/b/0/DisplayUnlockCaptcha\n","\n","import smtplib\n","\n","def SendEmail(msg):\n","    # store gmail password in my google drive (not the most secure way)\n","    # but it is much safer than storing it directly in this notebook, \n","    # and upload it to github for everyone to see\n","    with open('/content/gdrive/My Drive/Colab Notebooks/pw.txt') as file:\n","        data = file.readlines()\n","        \n","    gmail_user = 'alcidesft6@gmail.com'  \n","    gmail_password = data[0]\n","\n","    sent_from = gmail_user  \n","    to = ['alcidesft6@gmail.com']  \n","    subject = msg  \n","    body = '%s\\n\\n- Alcides Tiago' % msg\n","\n","    email_text = \\\n","\"\"\"From: %s\n","To: %s\n","Subject: %s\n","\n","%s\n","\"\"\" % (sent_from, \", \".join(to), subject, body)\n","\n","    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n","    server.ehlo()\n","    server.starttls()\n","    server.login(gmail_user, gmail_password)\n","    server.sendmail(sent_from, to, email_text)\n","    server.quit()\n","\n","    print(f'Email: \\n{email_text}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"At4UECHhz9Pp"},"source":["## Load Train Data"]},{"cell_type":"code","metadata":{"id":"Q29fijIfVZYv"},"source":["# import images\n","!cd /content\n","!git clone https://github.com/dctian/DeepPiCar\n","\n","!ls\n","data_dir = '/content/DeepPiCar/models/lane_navigation/data/images'\n","file_list = os.listdir(data_dir)\n","image_paths = []\n","steering_angles = []\n","pattern = \"*.png\"\n","for filename in file_list:\n","    if fnmatch.fnmatch(filename, pattern):\n","        image_paths.append(os.path.join(data_dir,filename))\n","        angle = int(filename[-7:-4])  # 092 part of video01_143_092.png is the angle. 90 is go straight\n","        steering_angles.append(angle)\n","\n","image_index = 20\n","plt.imshow(Image.open(image_paths[image_index]))\n","print(\"image_path: %s\" % image_paths[image_index] )\n","print(\"steering_Angle: %d\" % steering_angles[image_index] )\n","df = pd.DataFrame()\n","df['ImagePath'] = image_paths\n","df['Angle'] = steering_angles\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhsGlMrwVdE2"},"source":["# Look at the distribution of steering angle\n","num_of_bins = 25\n","samples_per_bin = 400\n","hist, bins = np.histogram(df['Angle'], num_of_bins)\n","\n","fig, axes = plt.subplots(1,1, figsize=(12,4))\n","axes.hist(df['Angle'], bins=num_of_bins, width=1, color='blue')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sc_Z4szldV8K"},"source":["Notice that the above diagram contains angeles mostly smaller than 90.  This makes sense, because in our training data, The car was mostly turning left.  This is going to fine, because we will balance the data by randomly flip the image, and the steering angle in the image generator process."]},{"cell_type":"code","metadata":{"id":"xPqHnXq1gWRC"},"source":["X_train, X_valid, y_train, y_valid = train_test_split( image_paths, steering_angles, test_size=0.2)\n","print(\"Training data: %d\\nValidation data: %d\" % (len(X_train), len(X_valid)))\n","\n","# plot the distributions of train and valid, make sure they are consistent\n","fig, axes = plt.subplots(1,2, figsize=(12,4))\n","axes[0].hist(y_train, bins=num_of_bins, width=1, color='blue')\n","axes[0].set_title('Training Data')\n","axes[1].hist(y_valid, bins=num_of_bins, width=1, color='red')\n","axes[1].set_title('Validation Data')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EaZEfJxdi796"},"source":["##Image Augumentation\n","Since we only have a few hundred images, to train a deep network, we need a lot more images.   Instead of running our car, let's try to augment our data. There are a couple of ways to do that.\n","\n","1. Zoom: crop out a smaller image from the center\n","1. Pan: crop out a smaller image from left or right side\n","1. adjust brightness of the image\n","1. flip the image horizontally, i.e do a left to right flip, and change the steering angle coorespondingly\n","1. introduce an Gaussian blur\n","\n","We can combine the above augmentation techniques to generate 100s times of the training images, with just a few hundred real images.\n","\n"]},{"cell_type":"code","metadata":{"id":"Yyx0sL2ekZoi"},"source":["def my_imread(image_path):\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    return image\n","\n","def zoom(image):\n","    zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n","    image = zoom.augment_image(image)\n","    return image\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_zoom = zoom(image_orig)\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_zoom)\n","axes[1].set_title(\"zoomed\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5ZAbxCDmnJM"},"source":["def pan(image):\n","    # pan left / right / up / down about 10%\n","    pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n","    image = pan.augment_image(image)\n","    return image\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_pan = pan(image_orig)\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_pan)\n","axes[1].set_title(\"panned\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eggszMEUnKHQ"},"source":["def adjust_brightness(image):\n","    # increase or decrease brightness by 30%\n","    brightness = img_aug.Multiply((0.7, 1.3))\n","    image = brightness.augment_image(image)\n","    return image\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_brightness = adjust_brightness(image_orig)\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_brightness)\n","axes[1].set_title(\"brightness adjusted\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAtWi8ix-L7R"},"source":["def blur(image):\n","    kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n","    image = cv2.blur(image,(kernel_size, kernel_size))\n","   \n","    return image\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_blur = blur(image_orig)\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_blur)\n","axes[1].set_title(\"blurred\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ags51OwPn3qR"},"source":["def random_flip(image, steering_angle):\n","    is_flip = random.randint(0, 1)\n","    if is_flip == 1:\n","        # randomly flip horizon\n","        image = cv2.flip(image,1)\n","        steering_angle = 180 - steering_angle\n","   \n","    return image, steering_angle\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_flip, steering_angle = random_flip(image_orig, steering_angles[image_index])\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_flip)\n","axes[1].set_title(\"flipped, angle=%s\" % steering_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdQIzXiuo5zD"},"source":["# put it together\n","def random_augment(image, steering_angle):\n","    if np.random.rand() < 0.5:\n","        image = pan(image)\n","    if np.random.rand() < 0.5:\n","        image = zoom(image)\n","    if np.random.rand() < 0.5:\n","        image = blur(image)\n","    if np.random.rand() < 0.5:\n","        image = adjust_brightness(image)\n","    image, steering_angle = random_flip(image, steering_angle)\n","    \n","    return image, steering_angle\n","\n","# show a few randomly augmented images\n","ncol = 2\n","nrow = 10\n","fig, axes = plt.subplots(nrow, ncol, figsize=(15, 50))\n","\n","for i in range(nrow):\n","    rand_index = random.randint(0, len(image_paths) - 1)\n","    image_path = image_paths[rand_index]\n","    steering_angle_orig = steering_angles[rand_index]\n","    \n","    image_orig = my_imread(image_path)\n","    image_aug, steering_angle_aug = random_augment(image_orig, steering_angle_orig)\n","    \n","    axes[i][0].imshow(image_orig)\n","    axes[i][0].set_title(\"original, angle=%s\" % steering_angle_orig)\n","    axes[i][1].imshow(image_aug)\n","    axes[i][1].set_title(\"augmented, angle=%s\" % steering_angle_aug)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xCtiEgo0C4S"},"source":["## Preprocess Training Data for Nvidia Model"]},{"cell_type":"code","metadata":{"id":"45-dWwTw0K5x"},"source":["def img_preprocess(image):\n","    height, _, _ = image.shape\n","    image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relavant for lane following\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n","    image = cv2.GaussianBlur(image, (3,3), 0)\n","    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n","    image = image / 255 # normalizing, the processed image becomes black for some reason.  do we need this?\n","    return image\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n","image_orig = my_imread(image_paths[image_index])\n","image_processed = img_preprocess(image_orig)\n","axes[0].imshow(image_orig)\n","axes[0].set_title(\"orig\")\n","axes[1].imshow(image_processed)\n","axes[1].set_title(\"processed\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"envGeErj0LfP"},"source":["## Create and Train Model"]},{"cell_type":"markdown","metadata":{"id":"0_mnzbPi7xPo"},"source":["This is the Nvidia CNN Model Architecture. The input layer is at the bottom with size of 200x66 in YUV color space ![](https://github.com/dctian/DeepPiCar/raw/master/models/lane_navigation/doc/NVidia%20Model%20Architecture.JPG) .\n","\n"]},{"cell_type":"code","metadata":{"id":"LB8_GDbn0VX4"},"source":["def nvidia_model():\n","    model = Sequential(name='Nvidia_Model')\n","    \n","    # elu=Expenential Linear Unit, similar to leaky Relu\n","    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n","    \n","    # Convolution Layers\n","    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n","    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n","    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n","    model.add(Conv2D(64, (3, 3), activation='elu')) \n","    model.add(Dropout(0.2)) # not in original model. added for more robustness\n","    model.add(Conv2D(64, (3, 3), activation='elu')) \n","    \n","    # Fully Connected Layers\n","    model.add(Flatten())\n","    model.add(Dropout(0.2)) # not in original model. added for more robustness\n","    model.add(Dense(100, activation='elu'))\n","    model.add(Dense(50, activation='elu'))\n","    model.add(Dense(10, activation='elu'))\n","    \n","    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n","    model.add(Dense(1)) \n","    \n","    # since this is a regression problem not classification problem,\n","    # we use MSE (Mean Squared Error) as loss function\n","    optimizer = Adam(lr=1e-3) # lr is learning rate\n","    model.compile(loss='mse', optimizer=optimizer)\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-FjHgMhA2vl"},"source":["model = nvidia_model()\n","print(model.summary())\n","# check at we will have 252,219 trainable parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQwQSh5fzEwy"},"source":["def image_data_generator(image_paths, steering_angles, batch_size, is_training):\n","    while True:\n","        batch_images = []\n","        batch_steering_angles = []\n","        \n","        for i in range(batch_size):\n","            random_index = random.randint(0, len(image_paths) - 1)\n","            image_path = image_paths[random_index]\n","            image = my_imread(image_paths[random_index])\n","            steering_angle = steering_angles[random_index]\n","            if is_training:\n","                # training: augment image\n","                image, steering_angle = random_augment(image, steering_angle)\n","              \n","            image = img_preprocess(image)\n","            batch_images.append(image)\n","            batch_steering_angles.append(steering_angle)\n","            \n","        yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n","            \n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rvVKC_M1kUu"},"source":["ncol = 2\n","nrow = 2\n","\n","X_train_batch, y_train_batch = next(image_data_generator(X_train, y_train, nrow, True))\n","X_valid_batch, y_valid_batch = next(image_data_generator(X_valid, y_valid, nrow, False))\n","\n","fig, axes = plt.subplots(nrow, ncol, figsize=(15, 6))\n","fig.tight_layout()\n","\n","for i in range(nrow):\n","    axes[i][0].imshow(X_train_batch[i])\n","    axes[i][0].set_title(\"training, angle=%s\" % y_train_batch[i])\n","    axes[i][1].imshow(X_valid_batch[i])\n","    axes[i][1].set_title(\"validation, angle=%s\" % y_valid_batch[i])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sf3x_HDiM0ei"},"source":["# start Tensorboard before model fit, so we can see the epoch tick in Tensorboard\n","# Jupyter Notebook embedded Tensorboard is a new feature in TF 2.0!!  \n","\n","# clean up log folder for tensorboard\n","log_dir_root = f'{model_output_dir}/logs/'\n","#!rm -rf $log_dir_root\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knb7Cx1ze_t0"},"source":["# this block prevents the training from starting if we Run All\n","DO_NOT_RUN_ALL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cLqWYTGA3PG"},"source":["# saves the model weights after each epoch if the validation loss decreased\n","checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_output_dir,'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n","\n","SendEmail(\"lane nav train started\")\n","history = model.fit_generator(image_data_generator( X_train, y_train, batch_size=100, is_training=True),\n","                              steps_per_epoch=300,\n","                              epochs=10,\n","                              validation_data = image_data_generator( X_valid, y_valid, batch_size=100, is_training=False),\n","                              validation_steps=200,\n","                              verbose=1,\n","                              shuffle=1,\n","                              callbacks=[checkpoint_callback])\n","# always save model output as soon as model finishes training\n","model.save(os.path.join(model_output_dir,'lane_navigation_final.h5'))\n","\n","date_str = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n","history_path = os.path.join(model_output_dir,'history.pickle')\n","with open(history_path, 'wb') as f:\n","    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n","    \n","SendEmail(\"lane nav train finished. val_loss from %.1f to %.1f\" % (history.history['val_loss'][0], history.history['val_loss'][-1]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MB5VJmU0Vqu"},"source":["## Check Trained Model on Validation Data"]},{"cell_type":"code","metadata":{"id":"XUNqiczguJx4"},"source":["history.history\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cf8ls0EodC4v"},"source":["# plot training and validation losses\n","# this should be the same as tensorboard\n","history_path = os.path.join(model_output_dir,'history.pickle')\n","with open(history_path, 'rb') as f:\n","    history = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KH_xNvr_A3ak"},"source":["history\n","plt.plot(history['loss'],color='blue')\n","plt.plot(history['val_loss'],color='red')\n","plt.legend([\"training loss\", \"validation loss\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7IrK0KPf8uk"},"source":["from sklearn.metrics import mean_squared_error, r2_score\n","\n","def summarize_prediction(Y_true, Y_pred):\n","    \n","    mse = mean_squared_error(Y_true, Y_pred)\n","    r_squared = r2_score(Y_true, Y_pred)\n","    \n","    print(f'mse       = {mse:.2}')\n","    print(f'r_squared = {r_squared:.2%}')\n","    print()\n","    \n","def predict_and_summarize(X, Y):\n","    model = load_model(f'{model_output_dir}/lane_navigation_check.h5')\n","    Y_pred = model.predict(X)\n","    summarize_prediction(Y, Y_pred)\n","    return Y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g238xj_XhymB"},"source":["n_tests = 100\n","X_test, y_test = next(image_data_generator(X_valid, y_valid, 100, False))\n","\n","y_pred = predict_and_summarize(X_test, y_test)\n","\n","n_tests_show = 2\n","fig, axes = plt.subplots(n_tests_show, 1, figsize=(10, 4 * n_tests_show))\n","for i in range(n_tests_show):\n","    axes[i].imshow(X_test[i])\n","    axes[i].set_title(f\"actual angle={y_test[i]}, predicted angle={int(y_pred[i])}, diff = {int(y_pred[i])-y_test[i]}\")\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ZuSW6vknulN"},"source":["As we can see the $R^2$ of the predicted was around 95% and Mean Squared Errors (MSE) are low, indicating the model is predicting a steering angle every simliar to our hand coded land follower, which was used as the model input. "]}]}